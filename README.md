

---

#  **Proyecto de Multicore â€“ Web Scraping**

### *CatÃ¡logo DinÃ¡mico de Videojuegos con Paralelismo y GitHub Pages*

![alt text](image-2.png)

---

## ğŸ“¸ Vista previa del proyecto

### ğŸ”¹ **PÃ¡gina principal**

![alt text](image.png)

### ğŸ”¹ **Vista de detalle de juego**

![alt text](image-1.png)



---

# ğŸ“Œ **DescripciÃ³n General**

Este proyecto combina **Web Scraping**, **Paralelismo**, **Procesamiento automÃ¡tico de datos** y **GitHub Pages** para generar un **catÃ¡logo dinÃ¡mico de videojuegos**, completamente actualizado cada 3 minutos.

Toda la informaciÃ³n se almacena en JSON y luego se muestra en una pÃ¡gina web moderna, elegante e interactiva.

---

# ğŸ§© **Problema Presentado**

En la industria del software, es comÃºn que existan plataformas que ofrecen productos (como videojuegos), pero:

### âŒ Problemas identificados:

* La informaciÃ³n de precios cambia constantemente.
* Los juegos aparecen en varias tiendas con descuentos diferentes.
* No existe un catÃ¡logo centralizado que recopile datos reales desde mÃºltiples plataformas.
* Se debe procesar gran cantidad de URLs â†’ **costoso sin paralelismo**.


---

# âœ… **SoluciÃ³n Implementada**

Se construyÃ³ un sistema completamente automatizado que:

### ğŸ”¹ **1. Realiza Web Scraping en Paralelo**

Usa **tres niveles de paralelismo**:

1. **Primer nivel:** extracciÃ³n de nombres
2. **Segundo nivel:** extracciÃ³n de precios, descuentos e imÃ¡genes
3. **Tercer nivel:** duraciÃ³n aproximada (HowLongToBeat), calificaciones, formato, etc.

Esto permite procesar cientos de juegos en minutos.

---

### ğŸ”¹ **2. Recopila datos de 3 plataformas reales**

* **Steam**
* **GOG**
* **GMG (Green Man Gaming)**



---

### ğŸ”¹ **3. Actualiza GitHub automÃ¡ticamente**

Cada vez que el scraper finaliza:

```
git add results.json results.csv
git commit -m "Actualizar datos ..."
git push
```

Esto significa que **la pÃ¡gina web SIEMPRE muestra datos recientes**.

---

### ğŸ”¹ **4. PublicaciÃ³n AutomÃ¡tica con GitHub Pages**

GitHub Pages lee siempre el archivo:

```
index.html
```

Y la web se actualiza automÃ¡ticamente cuando `results.json` cambia.

---

# âš™ **Procesamiento del Proyecto**

## ğŸ”¸ Flujo de EjecuciÃ³n

1. Se recolectan cientos de URLs por tienda (seeders)
2. Se procesan con **paralelismo controlado**
3. Se extraen datos reales de cada pÃ¡gina
4. Utilizar los mejores precios recopilados
5. Se genera:

   * `results.json`
   * `results.csv`
6. Se mandan los datos automÃ¡ticamente a GitHub
7. La web se actualiza con la nueva informaciÃ³n

---

# ğŸ§  **TecnologÃ­as Utilizadas**

### **Backend / Scraper**

* Python 3
* `aiohttp` â†’ descargas en paralelo
* `aiofiles` â†’ guardado asincrÃ³nico
* `BeautifulSoup4` + `lxml` â†’ parsing HTML
* `subprocess` â†’ push automÃ¡tico a GitHub
* Manejo de errores avanzado
* Expresiones regulares

### **Frontend**

* HTML5 + CSS3
* JavaScript Vanilla
* GitHub Pages (Deploy automÃ¡tico)

---

# ğŸŒ **PÃ¡gina Web (CatÃ¡logo de Juegos)**

La web:

âœ” Filtra por tienda
âœ” Filtra por formato (Digital / FÃ­sico)
âœ” Filtra por plataforma (PC, PS4, PS5, Xbox, etc.)
âœ” Ordena por precio, nombre, descuento, rating
âœ” Busca por nombre
âœ” Muestra detalles ampliados
âœ” Linkea a la tienda original

---

# ğŸš€ **CÃ³mo Ejecutar el Scraper**

### 1ï¸âƒ£ Instalar dependencias

```bash
pip install aiohttp aiofiles beautifulsoup4 lxml
```

### 2ï¸âƒ£ Ejecutar

```bash
python datos.py
```

El programa:

* Corre indefinidamente
* Recolecta datos cada 3 minutos
* Hace `git push` automÃ¡ticamente

---

# ğŸ“˜ **CÃ³mo Publicar la Web en GitHub Pages**

1. Subir el archivo **index.html**, `results.json` y el scraper a la raÃ­z del repositorio
2. Entrar a **Settings â†’ Pages**
3. Configurar

```
Source: main
Folder: /(root)
```

4. Guardar los cambios

La pagina web aparecere en:

```
https://danny7w7-coder.github.io/proyecto-multicore-web/
```

---

# ğŸ”§ **Uso de GitHub paso a paso (para principiantes)**

### âœ” Clonar repositorio

```bash
git clone https://github.com/usuario/repositorio.git
```

### âœ” Agregar cambios

```bash
git add .
```

### âœ” Guardar cambios

```bash
git commit -m "Mi actualizaciÃ³n"
```

### âœ” Subir a GitHub

```bash
git push
```

### âœ” Descargar cambios remotos

```bash
git pull
```

---

# ğŸ‘¤ **Autores del Proyecto**

### **Valeria Rojas Barrantes**

Estudiante de IngenierÃ­a en Computadores â€” TEC

### **Dylan MÃ©ndez Zamora**

Estudiante de IngenierÃ­a en Computadores â€” TEC

### **Danny GonzÃ¡lez Molina**

Estudiante de IngenierÃ­a en Computadores â€” TEC

---

# ğŸ **ConclusiÃ³n**

Este proyecto demuestra cÃ³mo combinar:

* **Paralelismo**
* **Web Scraping**
* **AutomatizaciÃ³n**
* **PublicaciÃ³n continua**
* **Frontend dinÃ¡mico**
